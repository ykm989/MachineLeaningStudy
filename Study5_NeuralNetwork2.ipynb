{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 흭득하는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습 문제는 데이터를 **훈련 데이터(training data)**와 **시험 데이터(test data)**로 나눠 학습과 시험을 수행하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통의 진행은 훈련 데이터만 사용하여 학습하면서 최적의 매개변수를 찾습니다. 그 후 시험 데이터를 사용하여 앞서 훈련한 모델의 실력을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 하는 이유는 **범용 능력**을 제대로 평가하기 위함입니다.\n",
    "**범용 능력** : 학습 하지 못한 데이터도 올바르게 푸는 능력\n",
    "\n",
    "하지만 그렇다고 한 데이터셋으로만 지나치게 최적화 되면 **오버피팅**이라는 문제가 생깁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능의 '나쁨'을 나타내는 지표로 일반적으로 평군 제곱 오차와 교차 엔트로피 오차를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균 제곱 오차  \n",
    "\n",
    "E = 1/2 * (sum(yk -tk) ** 2)  \n",
    "yk = 신경망의 출력  \n",
    "tk = 정답 레이블  \n",
    "k는 데이터의 차원 수를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, k):\n",
    "    return 0.5 * np.sum((y-k)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차  \n",
    "  \n",
    "E = -(sum(tk * log yk))  \n",
    "yk = 신경망의 출력  \n",
    "tk = 정답 레이블(one-hot-encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실상 정답 레이일 때로 추정되면 자연로그를 계산하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 작은 값인 delta를 더하는 이유는 np.log()에 0을 입력하면 -inf가 출력된다.  \n",
    "이를 방지하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-f6e7c0610b57>:1: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답일 시 출력되는 값이 더 낮다.  \n",
    "기계학습은 훈련 데이터에 대한 손실 함수의 값을 구해서 매개변수를 정정한다.  \n",
    "만약 100개의 훈련 데이터가 존재 한다면 각각 손실 함수를 구한 후 그 값의 합을 지표로 삼는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수의 합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 엔트로피 오차의 합 식  \n",
    "E = -(1/N * sum(sum(tnk * log ynk)))  \n",
    "\n",
    "N = 데이터의 갯수  \n",
    "tnk = n번째 데이터의 k번째 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 데이터의 손실함수 값의 합을 구하는 것은 힘든다.(배치의 양이 너무 크다.)  \n",
    "그렇기 때문에 훈련 데이터의 일부만 골라 추정치를 구한다.(일부만 뽑는다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST를 이용한 미니배치 학습 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_size = x_train.shape[0] # 60000\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 트레이닝 데이터 중 batch_size만큼을 뽑는다.\n",
    "x_batch = x_train[batch_mask]\n",
    "y_batch = y_train[batch_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 하나당 교차 엔트로피 오차를 구하는 교차 엔트로피 오차 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = t.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shpae[0]\n",
    "    return -np.sum(np.log(y[np.arang(batch_size), t] + 1e - 7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수를 사용하는 이유  \n",
    "  \n",
    "정확도나 계단 함수를 사용하면 가중치의 작은 변화에 따른 연속적인 변화가 나타나지 않는다.  \n",
    "하지만 시그모이드 함수와 같은 손실 함수는 작은 가중치 변화에도 연속적인 변화가 나타난ㄷ.  \n",
    "시그모이드의 함수의 미분은 어느 장소라도 0이 되지는 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사법(경사 하강법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현 위치에서 기울어진 방향으로 일정 거리만큼 이동하고 그 곳에서 기울기를 구해서 나아가는 식으로 반복해 함수의 값을 점차 줄이는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기울기** : 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향이다.  \n",
    "기울기를 이용하여 함수의 최솟값을 찾고자 하는 방법  \n",
    "\n",
    "함수가 극솟값, 최소값, 안장점일 시 기울기는 0이다.  \n",
    "극솟값 : 한정된 범위에서의 최솟값인 점  \n",
    "안장점 : 어느 방향에서 보면 극댓값이고 다른 방향에서 보면 극솟값이 되는 점  \n",
    "\n",
    "주의할점은 기울기가 가리키는 곳이 꼭 최솟값이라는 보장이 없다. 또, 복잡하고 찌그러진 모양의 함수라면 평평한 곳으로 파고들면서 **Plateau**라 하느, 학습이 진행되지 않는 정체기에 빠질 수 있다.  \n",
    "하지만 기울기가 가리키는 방향으로 나아가야 함수의 값을 줄일 수 있어서 이 정보를 단서로 나아갈 방향을 정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*최솟값을 찾으면 경사 하강법, 최댓값을 찾으면 경사 상승법*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사법의 수식  \n",
    "x = x - η * (af / ax0)  \n",
    "\n",
    "η(eta) = 갱신하는 양(학습률)  \n",
    "\n",
    "보통 η값을 미리 정해두는데 너무 크거나 작으면 '좋은 장소'를 찾아갈 수 없다. 신경망 학습에서는 보통 이 η값을 변경하면서 올바르게 학습하고 있는지를 확인하면서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "\n",
    "    for i in range(step_num):\n",
    "        x_history.append( x.copy() )\n",
    "\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x, np.array(x_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):#기울기 구하는 함수\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_var = x[idx] \n",
    "        \n",
    "        x[idx] = tmp_var + h #f(x+h)계산\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_var - h #f(x-h)계산\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
    "        x[idx] = tmp_var # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사법으로 f(x0, x1) = x0** 2 + x1** 2의 최솟값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "x, x_history = gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률이 너무 큰 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "x, x_history = gradient_descent(function_2, init_x = init_x, lr = 10.0, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 값을 발산해버린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률이 너무 작은 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "x, x_history = gradient_descent(function_2, init_x = init_x, lr = 1e-10, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "거의 갱신되지 않고 끝난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하이퍼파라미터(초매개변수)** : 학습률 같은 매개변수를 의미  \n",
    "가중치와 편향 같은 신경망의 매개변수와는 성질이 다른 매개변수이다.  \n",
    "신경망의 가중치 매개변수는 훈련 데이터와 학습 알고리즘에 의해서 '자동'으로 흭득되는 매개변수인 반면, 학습률 같은 하이퍼파라미터는 사람이 직접 서렂애향 하는 매개변수이다.이 하이퍼파라미터들은 여러 후보 값 중에서 시험을 통해 가장 잘 학습하는 값을 찾는 과정을 거쳐야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        \n",
    "        #가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.parmas['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        t = np.argmax(t, axis = 1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exe(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sofrtmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_a = np.exp(x - c)\n",
    "    sum_exp = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size = 100, output_size = 10)\n",
    "net.params['W1'].shape\n",
    "net.params['b1'].shape\n",
    "net.params['W2'].shape\n",
    "net.params['b2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시험 데이터 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TwoLayerNet' object has no attribute 'parmas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-34bf004f177f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mt_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'W2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7799f7f046df>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7d272356da0f>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_var\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m \u001b[1;31m#f(x+h)계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mfxh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_var\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m \u001b[1;31m#f(x-h)계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7799f7f046df>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7799f7f046df>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7799f7f046df>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparmas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TwoLayerNet' object has no attribute 'parmas'"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
    "\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc : \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
